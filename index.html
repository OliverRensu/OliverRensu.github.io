<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Sucheng Ren</title>

  <meta name="author" content="Sucheng Ren">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Sucheng (Oliver) Ren</name>
                  </p>
                  <p>
                    I am a postgraduate student advised by <a href="http://www.shengfenghe.com/">Shengfeng He</a> in South China University of Technology where I recieved my B.S. degree, expecting to get my M.S. degree
                    in Computer Science in June, 2022.
                  </p>
                  <p>
                    I work as an
                    intern in Tsinghua University, advised by Prof. <a href="http://people.csail.mit.edu/hangzhao/">Hang Zhao</a>. 
                    I am interested in segmentation, knowledge distillation and multimodal learning.
                  </p>
                  <p>
                    <font color='red'>I am looking for positions for PhD in 2022 Fall. If you have available positions, please
                    contact me. I am always ready to have a chatüòÄ</font>
                  </p>

                  <p style="text-align:center">
                    <a href="mailto:oliverrensu@gmail.com">Email</a> &nbsp|&nbsp
                    <a href="data/Sucheng_Ren_cv.pdf">CV</a> &nbsp|&nbsp
                    <a href="https://scholar.google.com/citations?user=Hbf-SoAAAAAJ&hl=zh-CN">Scholar</a> &nbsp|&nbsp
                    <a href="https://github.com/OliverRensu">Github</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/profile.jpg"><img style="width:100%;max-width:100%" alt="profile photo"
                      src="images/profile.jpg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>



          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <heading>News</heading>
                </td>
              </tr>
            </tbody>
          </table>
          <table width="100%" align="center" border="0" cellpadding="20">
            <tbody>
              <ul>
                <li>[Mar 2021] Three papers are accepted by CVPR2021 including two first author papers!üéâ</li>
                <li>[Dec 2020] Going to work with Prof. Hang Zhao in Tsinghua as a research intern!üë©‚Äçüíª</li>
                <li>[Jul 2020] A first author paper is accepted by ECCV2020 as spotlight paper (Acceptance Rate 5.0%)!üéâ</li>
              </ul>
            </tbody>
          </table>



          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Research</heading>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr onmouseout="end_user_stop()" onmouseover="end_user_start()">
                <td style="padding:20px;width:25%;vertical-align:left">
                  <div><img src="images/lipreading.png"></div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                    <papertitle>Learning from the Master: Distilling Cross-modal Advanced Knowledge for Lip Reading                      
                    </papertitle>
                  <br>
                  <br>
                  <strong>Sucheng Ren, </strong>
                  Yong Du,
                  Jianming Lv,
                  Guoqiang Han, 
                  and <a href="http://www.shengfenghe.com">Shengfeng He</a>

                  <br>
                  <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong></em>, 2021
                  <br>
                  [paper]
                  <!--<a href="https://arxiv.org/pdf/2012.01050.pdf">[paper]</a>-->
                  <a href="data/lipreading.bib">[bibtex]</a>
                  <p>
                    Training a master to learn how to teach a better student.
                  </p>
                </td>
              </tr>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr onmouseout="end_user_stop()" onmouseover="end_user_start()">
                <td style="padding:24px;width:25%;vertical-align:left">
                  <div><img src="images/RTM.png"></div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                    <papertitle>Reciprocal Transformations for Unsupervised Video Object Segmentation
                    </papertitle>
                  </a>
                  <br>
                  <strong>Sucheng Ren,</strong>
                  Wenxi Liu,
                  Yongtuo Liu,
                  Haoxin Chen,
                  Guoqiang Han and
                  <a href="http://www.shengfenghe.com">Shengfeng He</a>

                  <br>
                  <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong></em>, 2021
                  <br>
                  Code and dataset coming soon.
                  <br>
                  [paper]
                  <!--<a href="https://arxiv.org/pdf/2012.01050.pdf">[paper]</a>-->
                  <a href="data/RTM.bib">[bibtex]</a>
                  <a href="https://github.com/OliverRensu/RTNet">[code]</a>
                  <p>
                    Jointly learning salient objects, moving objects, recurring objects for Unsupervised Video Object Segmentation.
                  </p>
                </td>
              </tr>
          </table>
          
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr onmouseout="end_user_stop()" onmouseover="end_user_start()">
                <td style="padding:28px;width:25%;vertical-align:left">
                  <div><img src="images/FVOS.png"></div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                    <papertitle>Delving Deep into Many-to-many Attention forFew-shot Video Object Segmentation
                    </papertitle>
                  </a>
                  <br>
                  Haoxin Chen, Hanjie Wu, Nanxuan Zhao, <strong>Sucheng Ren</strong> and
                  <a href="http://www.shengfenghe.com">Shengfeng He</a>

                  <br>
                  <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong></em>, 2021
                  <br>
                  <!--<a href="https://arxiv.org/abs/2007.09943">[paper]</a>!-->
                  [paper]
                  <a href="data/DANet.bib">[bibtex]</a>
                  <a href="https://github.com/scutpaul/DANet">[code]</a>
                  <p>
                    
                  </p>
                </td>
              </tr>
          </table>
          
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr onmouseout="end_user_stop()" onmouseover="end_user_start()">
                <td style="padding:24px;width:25%;vertical-align:left">
                  <div><img src="images/TENET.png"></div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                    <papertitle>TENet: Triple Excitation Network for Video Salient Object Detection
                    </papertitle>
                  </a>
                  <br>
                  <strong>Sucheng Ren,</strong>
                  Chu Han,
                  Xin Yang,
                  Guoqiang Han and
                  <a href="http://www.shengfenghe.com">Shengfeng He</a>

                  <br>
                  <em>European Conference on Computer Vision <strong>(ECCV)</strong></em>, 2020
                  <br>
                  (Spotlight Oral, Acceptance Rate 5.0%)
                  <br>
                  <a href="https://arxiv.org/abs/2007.09943">[paper]</a>
                  <a href="data/TENet.bib">[bibtex]</a>
                  <p>
                    
                  </p>
                </td>
              </tr>
          </table>

          



  

</html>